{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "layout: post\n",
    "title: Virtebi Algorithm and Hidden Markov Model - Part 2\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've implemented virtebi algorithm and explain the advantage from naive approach at last post. Now it's time to look at another use case example: the Part of Speech Tagging! \n",
    "\n",
    "# POS Tag\n",
    "Part of Speech Tag ([POS Tag](https://en.wikipedia.org/wiki/Part-of-speech_tagging) / Grammatical Tag) is a part of natural language processing task. The main problem is \n",
    "> \"given a sequence of word, what are the postags for these words?\". \n",
    "\n",
    "\n",
    "### Example of POS Tag \n",
    "If you understand this writing, I'm pretty sure you have heard categorization of words, like: noun, verb, adjective, etc. Well, those are POS Tag! But then we now have more POS Tag then you have teached in English! (you can see [here](http://universaldependencies.org/u/pos/))\n",
    "\n",
    "For example this word:\n",
    "\n",
    "    **\"I like sushi\"**\n",
    "\n",
    "could be broken down into:\n",
    "\n",
    "| I |like | sushi|\n",
    "|--|--|--|\n",
    "| PRON | VERB | NOUN |\n",
    "\n",
    "Where,\n",
    "\n",
    "PRON = pronoun\n",
    "\n",
    "VERB = verb\n",
    "\n",
    "NOUN = noun\n",
    "\n",
    "\n",
    "\n",
    "# So how to answer the real question here? \n",
    "\n",
    "One way to model on how to get the answer, is by:\n",
    "$$\n",
    "    P(pos\\space tag \\space sequence \\space | \\space words \\space sequence) = \\prod_{i=1}^{I}{P(tag\\space |\\space word_{w})}\n",
    "$$\n",
    "\n",
    "\n",
    "# Hidden Markov Model using Pomegranate\n",
    "We can impelement this model with Hidden Markov Model. For this experiment, I will use [pomegranate](https://pomegranate.readthedocs.io/en/latest/HiddenMarkovModel.html#hiddenmarkovmodel) library instead of developing on our own code like on the post before. It will enable us to construct the model faster and with more intuitive definition. I will walk you through the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# I will use nltk library with brown corpus as example\n",
    "import nltk\n",
    "import nltk.corpus as corp\n",
    "\n",
    "import pomegranate as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the corpus from nltk repository\n",
    "if not corp.brown:\n",
    "    nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown corpus has 1,161,192 tagged words / unigram\n"
     ]
    }
   ],
   "source": [
    "print('Brown corpus has {:,} tagged words / unigram'.format(len(corp.brown.tagged_words())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see sneak peak from tagged words\n",
    "corp.brown.tagged_words()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have sample: 5000 tokens\n"
     ]
    }
   ],
   "source": [
    "# sampling for the first 5000 tokens just for demo sake\n",
    "sample = corp.brown.tagged_words()[:5000]\n",
    "print('We have sample: {} tokens'.format(len(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_discrete_distributions_per_tag(tagged_tokens):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    -------\n",
    "    tagged_tokens: list of tagged tokens in form like:\n",
    "            [('The', 'AT'),\n",
    "             ('Fulton', 'NP-TL'),\n",
    "             ('County', 'NN-TL'),\n",
    "             ('Grand', 'JJ-TL'),\n",
    "             ('Jury', 'NN-TL'),\n",
    "             ('said', 'VBD'),\n",
    "             ('Friday', 'NR'),\n",
    "             ('an', 'AT'),\n",
    "             ('investigation', 'NN'),\n",
    "             ('of', 'IN')]\n",
    "    \n",
    "    This function will generate initial probability for each tag\n",
    "    \"\"\"\n",
    "    tag_probs = dict()\n",
    "    for token, tag in tagged_tokens:\n",
    "        if tag not in tag_probs:\n",
    "            tag_probs[tag] = dict()\n",
    "            tag_probs[tag]['count_tag'] = dict()\n",
    "            tag_probs[tag]['occurence'] = 1\n",
    "        else:\n",
    "            tag_probs[tag]['occurence'] += 1\n",
    "            \n",
    "        if token not in tag_probs[tag]['count_tag']:\n",
    "            tag_probs[tag]['count_tag'][token] = 1\n",
    "        else:\n",
    "            tag_probs[tag]['count_tag'][token] += 1\n",
    "            \n",
    "    for tag in tag_probs:\n",
    "        tag_probs[tag]['probs'] = dict()\n",
    "        for token in tag_probs[tag]['count_tag']:\n",
    "            tag_probs[tag]['probs'][token] = float(tag_probs[tag]['count_tag'][token]) / float(tag_probs[tag]['occurence'])\n",
    "    \n",
    "    return tag_probs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_transition_probabilities_per_tag(tagged_tokens):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    -------\n",
    "    tagged_tokens: list of tagged tokens in form like:\n",
    "            [('The', 'AT'),\n",
    "             ('Fulton', 'NP-TL'),\n",
    "             ('County', 'NN-TL'),\n",
    "             ('Grand', 'JJ-TL'),\n",
    "             ('Jury', 'NN-TL'),\n",
    "             ('said', 'VBD'),\n",
    "             ('Friday', 'NR'),\n",
    "             ('an', 'AT'),\n",
    "             ('investigation', 'NN'),\n",
    "             ('of', 'IN')]\n",
    "             \n",
    "    This function will generate the emission matrix / probabilities for each tag\n",
    "        \n",
    "    \"\"\"\n",
    "    transition_probs = dict()\n",
    "    for i in range(len(tagged_tokens)):\n",
    "        current_tag = tagged_tokens[i][1]\n",
    "        if current_tag not in transition_probs:\n",
    "            transition_probs[current_tag] = dict()\n",
    "            transition_probs[current_tag]['occurence'] = 0\n",
    "            transition_probs[current_tag]['count_transition'] = dict()\n",
    "        \n",
    "        # evaluate previous tag\n",
    "        if i > 0:\n",
    "            previous_tag = tagged_tokens[i-1][1]\n",
    "            pt = tagged_tokens[i-1][0]\n",
    "            transition_probs[previous_tag]['occurence'] += 1\n",
    "            \n",
    "            # special case for <start> tag\n",
    "            if pt == '.':\n",
    "                if '<start>' not in transition_probs:\n",
    "                    transition_probs['<start>'] = dict()\n",
    "                    transition_probs['<start>']['occurence'] = 0\n",
    "                    transition_probs['<start>']['count_transition'] = dict()\n",
    "                if current_tag not in transition_probs['<start>']['count_transition']:\n",
    "                    transition_probs['<start>']['count_transition'][current_tag] = 0\n",
    "                    \n",
    "                transition_probs['<start>']['count_transition'][current_tag] += 1\n",
    "                transition_probs['<start>']['occurence'] += 1\n",
    "                    \n",
    "            \n",
    "            #init\n",
    "            if current_tag not in transition_probs[previous_tag]['count_transition']:\n",
    "                transition_probs[previous_tag]['count_transition'][current_tag] = 0\n",
    "                \n",
    "            transition_probs[previous_tag]['count_transition'][current_tag] += 1\n",
    "    for tag in transition_probs:\n",
    "        transition_probs[tag]['probs'] = dict()\n",
    "        for transit_tag in transition_probs[tag]['count_transition']:\n",
    "            transition_probs[tag]['probs'][transit_tag] = \\\n",
    "                float(transition_probs[tag]['count_transition'][transit_tag]) / float(transition_probs[tag]['occurence'])\n",
    "    \n",
    "    return transition_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hmm_model(token_dist, transition_dist, model_name='hmm-tagger'):\n",
    "    state_dict = dict()\n",
    "    for token in token_dist:\n",
    "        state_dict[token] = \\\n",
    "            pm.State(\n",
    "                pm.DiscreteDistribution(\n",
    "                    token_dist[token]['probs']\n",
    "                )\n",
    "                , name=token\n",
    "            )\n",
    "            \n",
    "    model = pm.HiddenMarkovModel(model_name)\n",
    "    model.add_states(list(state_dict.values()))\n",
    "    \n",
    "    # initialization for starting tokens\n",
    "    for token, prob in transition_dist['.']['probs'].items():\n",
    "        model.add_transition(state_dict[token], model.end, prob)\n",
    "        \n",
    "    for token, prob in transition_dist['<start>']['probs'].items():\n",
    "        model.add_transition(model.start, state_dict[token], prob)\n",
    "    \n",
    "    transition_dist_list = list(transition_dist.items())\n",
    "    for i in range(1, len(transition_dist_list)):\n",
    "        ptoken, pmeta = transition_dist_list[i]\n",
    "        if ptoken != '.' and ptoken != '<start>':\n",
    "            for ctoken, cprob in pmeta['probs'].items():\n",
    "                \n",
    "                model.add_transition(\n",
    "                    state_dict[ptoken],\n",
    "                    state_dict[ctoken],\n",
    "                    cprob\n",
    "                )\n",
    "\n",
    "        \n",
    "    return model, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HmmTaggerModel(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    POS Tagger with Hmm Model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._inner_model = None\n",
    "        self._tag_dist = None\n",
    "        self._transition_dist = None\n",
    "        self._state_dict = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        expecting X as list of tokens, while y is list of POS tag\n",
    "        \"\"\"\n",
    "        combined = list(zip(X, y))\n",
    "        self._tag_dist = construct_discrete_distributions_per_tag(combined)\n",
    "        self._transition_dist = construct_transition_probabilities_per_tag(combined)\n",
    "        \n",
    "        self._inner_model, _ = build_hmm_model(self._tag_dist, self._transition_dist)\n",
    "        self._inner_model.bake()\n",
    "        \n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        expecting X as list of tokens\n",
    "        \"\"\"\n",
    "        return [state.name for i, state in self._inner_model.viterbi(X)[1]][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ypred, ytrue):\n",
    "    total = len(ytrue)\n",
    "    correct = 0\n",
    "    for pred, true in zip(ypred, ytrue):\n",
    "        if ypred == ytrue:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HmmTaggerModel()\n",
    "model.fit(map(lambda x: x[0], sample), map(lambda x: x[1], sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual words: The Fulton County Grand Jury said Friday an investigation of\n",
      "actual tags: AT NP-TL NN-TL JJ-TL NN-TL VBD NR AT NN IN\n",
      "predicted tags: AT NP-TL NN-TL JJ-TL NN-TL VBD NR AT NN IN\n",
      "============================================================\n",
      "actual words: The September-October term jury\n",
      "actual tags: AT NP NN NN\n",
      "predicted tags: AT NP NN NN\n",
      "============================================================\n",
      "mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "st_idx = [0, 68]\n",
    "end_idx = [10, 72]\n",
    "\n",
    "list_acc = list()\n",
    "for st, end in zip(st_idx, end_idx):\n",
    "    actual_words = list(map(lambda x: x[0], sample[st:end]))\n",
    "    actual = list(map(lambda x: x[1], sample[st:end]))\n",
    "    predicted = model.predict(\n",
    "            list(map(lambda x: x[0], sample[st:end]))\n",
    "        )\n",
    "    print('actual words: {}'.format(' '.join(actual_words)))\n",
    "    print('actual tags: {}'.format(' '.join(actual)))\n",
    "    print('predicted tags: {}'.format(' '.join(predicted)))\n",
    "    print('============================================================')\n",
    "    list_acc.append(accuracy(actual, predicted))\n",
    "mean_acc = np.mean(list_acc)\n",
    "\n",
    "print('mean accuracy: {}'.format(mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That went well! Now lets try for bigger corpuses! I wil use 500,000 words from the brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_sample = corp.brown.tagged_words()[:500000]\n",
    "model = HmmTaggerModel()\n",
    "model.fit(\n",
    "    map(lambda x: x[0], larger_sample), \n",
    "    map(lambda x: x[1], larger_sample)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual words: The Fulton County Grand Jury said Friday an investigation of\n",
      "actual tags: AT NP-TL NN-TL JJ-TL NN-TL VBD NR AT NN IN\n",
      "predicted tags: AT NP-TL NN-TL JJ-TL NN-TL VBD NR AT NN IN\n",
      "============================================================\n",
      "actual words: The September-October term jury\n",
      "actual tags: AT NP NN NN\n",
      "predicted tags: AT NP NN NN\n",
      "============================================================\n",
      "actual words: `` Only a relative handful of such reports was received '' , the jury said\n",
      "actual tags: `` RB AT JJ NN IN JJ NNS BEDZ VBN '' , AT NN VBD\n",
      "predicted tags: `` RB AT JJ NN IN JJ NNS BEDZ VBN '' , AT NN VBD\n",
      "============================================================\n",
      "mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "st_idx = [0, 68, 103]\n",
    "end_idx = [10, 72, 118]\n",
    "\n",
    "list_acc = list()\n",
    "for st, end in zip(st_idx, end_idx):\n",
    "    actual_words = list(map(lambda x: x[0], sample[st:end]))\n",
    "    actual = list(map(lambda x: x[1], sample[st:end]))\n",
    "    predicted = model.predict(\n",
    "            list(map(lambda x: x[0], sample[st:end]))\n",
    "        )\n",
    "    print('actual words: {}'.format(' '.join(actual_words)))\n",
    "    print('actual tags: {}'.format(' '.join(actual)))\n",
    "    print('predicted tags: {}'.format(' '.join(predicted)))\n",
    "    print('============================================================')\n",
    "    list_acc.append(accuracy(actual, predicted))\n",
    "mean_acc = np.mean(list_acc)\n",
    "\n",
    "print('mean accuracy: {}'.format(mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does make a good model!! Though it takes more time for larger model. \n",
    "\n",
    "## Is This a Perfect Model?\n",
    "But now you might wonder, is this the perfect model for POS tagging? Well congratulation! you asked a good question and the answer is No! It is not the perfect model. I have only showed you working case, but actually there will be problems:\n",
    "1. Out Of Vocabulary (OOV), where there are no matching word between input and training data. \n",
    "2. Training data without exhaustive positioning of tagging. This simple model will not be able to adjust it self if, let's say there is a word tagged as NP in the beginning of sentence, but this has never happened in training data. \n",
    "3. Lack of preprocessing, such as lower casing, punctuation removal, etc will make the model not focused enough into predicting POS tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclussion\n",
    "Even though HMM will produces a fairly good model for POS Tagging, but you need to watch for disadvantages for using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "- https://en.wikipedia.org/wiki/Brown_Corpus\n",
    "- https://pomegranate.readthedocs.io/en/latest/HiddenMarkovModel.html#hiddenmarkovmodel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
